\documentclass{beamer}

\usepackage{lads}
\setbeamertemplate{navigation symbols}{}

\title{Orthogonality}
\date{}
\author{BIOE 210}

\begin{document}

\maketitle

\begin{frame}
\frametitle{Vector Decomposition}

We decompose a vector \Vu\ over the vectors $\Vv_1$, $\Vv_2$, $\ldots$, $\Vv_n$ by finding scalars $a_1$, $a_2$, $\ldots$, $a_n$ such that

\[ \Vu = a_1\Vv_1 + a_2\Vv_2 + \cdots + a_n\Vv_n \]

Usually the vectors $\Vv_1$, $\Vv_2$, $\ldots$, $\Vv_n$ are easier to interpret than the vector \Vu. Decomposition helps us understand how vectors like \Vu\ can be constructed from simpler parts.
\end{frame}

\begin{frame}
\frametitle{Basis Vectors}

A set of $n$ vectors is a basis for a vector space if and only if
\begin{enumerate}
	\item The number of vectors ($n$) equals the dimension of the space.
	\item The vectors span the space.
	\item The vectors are linearly independent.
\end{enumerate}

Basis vectors are ideal sets for decomposing vectors since \emph{there is always a unique set of scalars that decompose any vector onto a basis.}	
\end{frame}

\begin{frame}
\frametitle{Decomposing Vectors}

How do we decompose the vector \Vu\ onto a basis $\Vv_1$, $\Vv_2$, $\ldots$, $\Vv_n$?
\begin{enumerate}
	\item Assemble a matrix \VV\ using the basis vectors as columns: 
		\[ \VV = \begin{pmatrix} \Vv_1 & \Vv_2 & \cdots & \Vv_n \end{pmatrix} \]
	\item Solve the linear system $\VV\Va = \Vu$ to find the scalars $a_1$, $a_2$, $\ldots$, $a_n$.
\end{enumerate}

Decomposing a vector onto a basis requires solving a linear system. Is there a simpler way?
\end{frame}

\begin{frame}
\frametitle{Orthonormal Basis Vectors}

Decomposing onto a basis is much easier if our basis is \emph{orthonormal}. An orthonormal basis has two additional requirements:
\begin{enumerate}
	\item The vectors are \emph{mutually orthogonal}, i.e. every vector in the basis is orthogonal to every other vector in the basis.
	\item Every vector in the basis is a unit vector.
\end{enumerate}
\end{frame}

\begin{frame}
\frametitle{Decomposing onto an Orthonormal Basis}

Given an orthonormal basis $\hv_1$, $\hv_2$, $\ldots$, $\hv_n$, the decomposition of the vector \Vu,
\[ \Vu = a_1\hv_1 + a_2\hv_2 + \cdots + a_n\hv_n \]
has coefficients
\begin{align*}
	a_1 &= \Vu\cdot\hv_1 \\
	a_2 &= \Vu\cdot\hv_2 \\
	\vdots \\
	a_n &= \Vu\cdot\hv_n
\end{align*}

Decomposing onto an orthonormal basis requires only dot products, not solving a linear system!
\end{frame}

\begin{frame}
\frametitle{Finding Orthonormal Basis Vectors}

Orthonormal basis vectors are great, but how do we find them? In the last part of the chapter we introduce the Gram-Schmidt algorithm for building an orthonormal set of vectors starting from a non-orthonormal set.

\medskip
Realize that the Gram-Schmidt algorithm produces a new set of vectors. If you want an orthonormal set that is ``close" to a starting set, use Gram-Schmidt. If you want to decompose a vector onto a non-orthonormal basis, you would still need to solve the linear system $\VV\Va=\Vu$.

\medskip
In the coming chapters we will show how orthonormal sets of vectors can be generated directly from matrices.
\end{frame}


\end{document}
